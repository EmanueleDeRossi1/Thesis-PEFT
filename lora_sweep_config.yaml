program: train.py
project: lora
##### CHANGE TO RANDOM #######
##############################
method: grid
##### CHANGE TO RANDOM #######
##############################
metric: 
    name: target_test/real_f1
    goal: maximize

# These are the hyparameters you selected with Matteo
# parameters:
#     learning_rate:
#         values: [1e-3, 1e-4, 1e-5]
#     # out of memory :(
#     batch_size:
#         values: [16]

#     lora_alpha:
#         values: [4, 32]
#     lora_r: 
#         values: [4, 32]
#     lora_dropout:
#         values: [0.1, 0.3]

# Prova con altri parametri
parameters:
    learning_rate:
        values: [1e-4]
    # out of memory :(
    batch_size:
        values: [32]

    lora_alpha:
        values: [32]
    lora_r: 
        values: [1,4]
    lora_dropout:
        values: [0.1]
    shuffle:
        values: [False]

# boh prova con ancora piu parametri
# parameters:
#     learning_rate:
#         values: [1e-3]
#     weight_decay:
#         values: [0.01]
#     # out of memory :(
#     batch_size:
#         values: [16]

#     lora_alpha:
#         values: [4, 64]
#     lora_r: 
#         values: [4, 64]
#     lora_dropout:
#         values: [0.01, 0.1]



# Try with the hparams on Sebastian's project
# parameters:
#     learning_rate:
#         values: [1e-3, 1e-4, 1e-5]
#     lora_alpha:
#         values: [8]
#     lora_r: 
#         values: [8]
#     lora_dropout:
#         values: [0.3, 0.5]
#     weight_decay:
#         values: [0.01]
#     # out of memory :(
#     batch_size:
#         values: [16]


#     weight_decay:
#         values: [0.001, 0.01, 0.1]


